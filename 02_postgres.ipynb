{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["# LSHRS Demo 2: PostgreSQL Integration & Reranking\n", "\n", "## Overview\n", "\n", "This notebook demonstrates a **production-grade workflow**:\n", "\n", "- **Streaming Data**: Load vectors directly from PostgreSQL\n", "- **Index Building**: Create LSH signatures and store them in Redis\n", "- **Two-Stage Search**:\n", "  1. Fast approximate matching using LSH\n", "  2. Accurate re-ranking using cosine similarity\n", "- **Performance vs Accuracy**: Observe the trade-off between speed and precision\n", "\n", "### Architecture\n", "\n", "```\n", "PostgreSQL (Cold Storage)  â†’  Streaming Iterator\n", "                                    â†“\n", "                          LSHRS (Hashing)\n", "                                    â†“\n", "                          Redis (Hot Index)\n", "                                    â†“\n", "                          Query Execution\n", "                             â”œâ”€ LSH Lookup (Fast)\n", "                             â””â”€ Cosine Rerank (Accurate)\n", "```"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["import numpy as np\n", "import pandas as pd\n", "import time\n", "import matplotlib.pyplot as plt\n", "from typing import List, Tuple, Dict\n", "\n", "# Database\n", "import psycopg2\n", "from sqlalchemy import create_engine, text\n", "\n", "# LSHRS\n", "from lshrs import LSHRS\n", "\n", "# Configuration\n", "DB_URL = \"postgresql://postgres:changeme@localhost:5432/demo\"\n", "REDIS_HOST = \"localhost\"\n", "REDIS_PORT = 6379\n", "DIM = 128\n", "NUM_PRODUCTS = 2000  # ~2K product embeddings\n", "SEED = 42\n", "\n", "print(\"âœ“ Imports successful\")\n", "print(f\"  Database URL: {DB_URL}\")\n", "print(f\"  Vector Dimension: {DIM}\")\n", "print(f\"  Target Product Count: {NUM_PRODUCTS}\")"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Section 1: Database Setup & Population\n", "\n", "Create a PostgreSQL table with product embeddings."]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["def setup_product_database():\n", "    \"\"\"Create products table with embeddings.\"\"\"\n", "    engine = create_engine(DB_URL)\n", "    \n", "    with engine.connect() as conn:\n", "        # Enable pgvector extension if available\n", "        try:\n", "            conn.execute(text(\"CREATE EXTENSION IF NOT EXISTS vector;\"))\n", "        except:\n", "            print(\"  Note: pgvector not available, using FLOAT[] arrays\")\n", "        \n", "        # Drop existing table\n", "        conn.execute(text(\"DROP TABLE IF EXISTS products CASCADE;\"))\n", "        \n", "        # Create table with embeddings\n", "        conn.execute(text(\"\"\"\n", "            CREATE TABLE products (\n", "                id SERIAL PRIMARY KEY,\n", "                sku VARCHAR(50) UNIQUE NOT NULL,\n", "                category VARCHAR(50) NOT NULL,\n", "                name VARCHAR(255) NOT NULL,\n", "                price DECIMAL(10, 2) NOT NULL,\n", "                embedding FLOAT[] NOT NULL,\n", "                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n", "            );\n", "        \"\"\"))\n", "        \n", "        # Create index on category for filtering\n", "        conn.execute(text(\"CREATE INDEX idx_products_category ON products(category);\"))\n", "        \n", "        conn.commit()\n", "        print(\"  âœ“ Table created\")\n", "\n", "# Run setup\n", "print(\"Setting up database...\")\n", "setup_product_database()"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Section 2: Generate Realistic Product Data\n", "\n", "Create synthetic product embeddings organized by category."]
    },
    {
      "cell_type": "code",
      "execute_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["def populate_products():\n", "    \"\"\"Generate synthetic products with category-specific embeddings.\"\"\"\n", "    engine = create_engine(DB_URL)\n", "    \n", "    categories = ['electronics', 'clothing', 'books', 'home', 'sports']\n", "    np.random.seed(SEED)\n", "    \n", "    products = []\n", "    \n", "    print(f\"Generating {NUM_PRODUCTS} products...\")\n", "    \n", "    for i in range(NUM_PRODUCTS):\n", "        # Assign category (products per category)\n", "        cat_idx = i % len(categories)\n", "        category = categories[cat_idx]\n", "        \n", "        # Create category-biased embedding\n", "        # Each category gets a bias in a different region of embedding space\n", "        embedding = np.random.randn(DIM).astype(np.float32) * 0.5\n", "        embedding[cat_idx * 25 : (cat_idx + 1) * 25] += np.random.randn(25).astype(np.float32) * 2.0\n", "        \n", "        products.append({\n", "            'sku': f'SKU-{i:06d}',\n", "            'category': category,\n", "            'name': f'{category.capitalize()} Product {i}',\n", "            'price': np.random.uniform(10, 1000),\n", "            'embedding': embedding.tolist()\n", "        })\n", "    \n", "    # Batch insert\n", "    with engine.connect() as conn:\n", "        conn.execute(\n", "            text(\"INSERT INTO products (sku, category, name, price, embedding) VALUES (:sku, :category, :name, :price, :embedding)\"),\n", "            products\n", "        )\n", "        conn.commit()\n", "    \n", "    print(f\"  âœ“ {NUM_PRODUCTS} products inserted\")\n", "\n", "populate_products()\n", "\n", "# Verify\n", "engine = create_engine(DB_URL)\n", "with engine.connect() as conn:\n", "    result = conn.execute(text(\"SELECT COUNT(*), COUNT(DISTINCT category) FROM products;\")).fetchone()\n", "    print(f\"  âœ“ Database check: {result[0]} products, {result[1]} categories\")"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Section 3: Define Vector Fetcher Callback\n", "\n", "LSHRS needs a way to retrieve full vectors for re-ranking. We define a callback that fetches from Postgres."]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["def fetch_vectors_from_db(indices: List[int]) -> np.ndarray:\n", "    \"\"\"\n", "    Fetch product embeddings from PostgreSQL.\n", "    \n", "    Args:\n", "        indices: List of product IDs\n", "    \n", "    Returns:\n", "        np.ndarray of shape (len(indices), DIM)\n", "    \"\"\"\n", "    if not indices:\n", "        return np.array([], dtype=np.float32).reshape(0, DIM)\n", "    \n", "    try:\n", "        conn = psycopg2.connect(DB_URL)\n", "        cur = conn.cursor()\n", "        \n", "        # Fetch embeddings\n", "        query = \"SELECT id, embedding FROM products WHERE id = ANY(%s) ORDER BY id;\"\n", "        cur.execute(query, (list(indices),))\n", "        rows = cur.fetchall()\n", "        \n", "        cur.close()\n", "        conn.close()\n", "        \n", "        # Reconstruct in correct order\n", "        lookup = {row[0]: np.array(row[1], dtype=np.float32) for row in rows}\n", "        vectors = np.array([lookup.get(idx, np.zeros(DIM, dtype=np.float32)) for idx in indices])\n", "        \n", "        return vectors.astype(np.float32)\n", "    except Exception as e:\n", "        print(f\"ERROR fetching vectors: {e}\")\n", "        return np.zeros((len(indices), DIM), dtype=np.float32)\n", "\n", "# Test the fetcher\n", "test_vectors = fetch_vectors_from_db([1, 2, 3])\n", "print(f\"âœ“ Vector fetcher functional\")\n", "print(f\"  Shape: {test_vectors.shape}\")\n", "print(f\"  Sample norm: {np.linalg.norm(test_vectors[0]):.4f}\")"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Section 4: Build LSH Index from PostgreSQL\n", "\n", "Stream vectors from Postgres and create the index."]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Initialize LSHRS\n", "lsh = LSHRS(\n", "    dim=DIM,\n", "    similarity_threshold=0.6,  # Balanced threshold\n", "    vector_fetch_fn=fetch_vectors_from_db,  # Enable re-ranking\n", "    redis_host=REDIS_HOST,\n", "    redis_port=REDIS_PORT,\n", "    redis_prefix='demo_pg',\n", "    seed=SEED\n", ")\n", "\n", "lsh.clear()\n", "\n", "# Display configuration\n", "stats = lsh.stats()\n", "print(f\"LSH Configuration:\")\n", "print(f\"  Bands: {stats['num_bands']}\")\n", "print(f\"  Rows/Band: {stats['rows_per_band']}\")\n", "print(f\"  Total Bits: {stats['num_bands'] * stats['rows_per_band']}\")\n", "print(f\"  Seed: {stats['seed']}\")\n", "\n", "# Stream from database\n", "print(f\"\\nStreaming from PostgreSQL...\")\n", "start_time = time.time()\n", "\n", "lsh.create_signatures(\n", "    format=\"postgres\",\n", "    dsn=DB_URL,\n", "    table=\"products\",\n", "    index_column=\"id\",\n", "    vector_column=\"embedding\",\n", "    batch_size=500,\n", "    where_clause=None  # Index all products\n", ")\n", "\n", "index_time = time.time() - start_time\n", "print(f\"âœ“ Indexing complete in {index_time:.2f}s\")\n", "print(f\"  Throughput: {NUM_PRODUCTS / index_time:.0f} vectors/sec\")"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Section 5: Query with Two-Stage Retrieval\n", "\n", "Execute queries and compare LSH-only vs LSH+Reranking."]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Get a query product\n", "engine = create_engine(DB_URL)\n", "with engine.connect() as conn:\n", "    result = conn.execute(text(\"SELECT id, name, category FROM products WHERE id = 1;\")).fetchone()\n", "    query_id, query_name, query_category = result\n", "\n", "query_vec = fetch_vectors_from_db([query_id])[0]\n", "\n", "print(f\"Query Product:\")\n", "print(f\"  ID: {query_id}\")\n", "print(f\"  Name: {query_name}\")\n", "print(f\"  Category: {query_category}\")\n", "print(f\"  Vector Norm: {np.linalg.norm(query_vec):.4f}\")\n", "\n", "# Stage 1: LSH-only (fast, approximate)\n", "print(f\"\\n{'='*60}\")\n", "print(f\"Stage 1: LSH Candidate Retrieval (Approximate)\")\n", "print(f\"{'='*60}\")\n", "\n", "t0 = time.time()\n", "lsh_candidates = lsh.get_top_k(query_vec, topk=50)\n", "lsh_time = (time.time() - t0) * 1000\n", "\n", "print(f\"âœ“ Retrieved {len(lsh_candidates)} candidates in {lsh_time:.2f}ms\")\n", "print(f\"  Candidates: {lsh_candidates[:10]}...\")\n", "\n", "# Stage 2: LSH+Reranking (slower, accurate)\n", "print(f\"\\n{'='*60}\")\n", "print(f\"Stage 2: LSH + Cosine Reranking (Accurate)\")\n", "print(f\"{'='*60}\")\n", "\n", "t0 = time.time()\n", "reranked_results = lsh.get_above_p(query_vec, p=0.05)  # Top 5% similarity\n", "rerank_time = (time.time() - t0) * 1000\n", "\n", "print(f\"âœ“ Retrieved {len(reranked_results)} results in {rerank_time:.2f}ms\")\n", "\n", "# Fetch product info for top results\n", "top_ids = [idx for idx, _ in reranked_results[:10]]\n", "with engine.connect() as conn:\n", "    query_str = \"SELECT id, name, category FROM products WHERE id = ANY(%s) ORDER BY id;\"\n", "    result = conn.execute(text(query_str), {'ids': top_ids}).fetchall()\n", "    product_info = {row[0]: (row[1], row[2]) for row in result}\n", "\n", "print(f\"\\nTop 10 Results (Ranked by Cosine Similarity):\")\n", "print(f\"Rank | ID  | Name                      | Category    | Similarity\")\n", "print(f\"-\"*70)\n", "\n", "for rank, (idx, score) in enumerate(reranked_results[:10], 1):\n", "    name, cat = product_info.get(idx, ('N/A', 'N/A'))\n", "    name = name[:23] if name else 'N/A'\n", "    print(f\"{rank:4d} | {idx:3d} | {name:25s} | {cat:11s} | {score:10.4f}\")\n", "\n", "# Comparison\n", "print(f\"\\n{'='*60}\")\n", "print(f\"Performance Comparison\")\n", "print(f\"{'='*60}\")\n", "print(f\"LSH Only (Top-K):      {lsh_time:7.2f}ms  ({len(lsh_candidates)} candidates)\")\n", "print(f\"LSH+Rerank (Top-P):    {rerank_time:7.2f}ms  ({len(reranked_results)} results)\")\n", "print(f\"Slowdown Factor:       {rerank_time/lsh_time:7.2f}x  (more accurate but slower)\")\n", "print(f\"\\nTrade-off: LSH is fast for candidate filtering, re-ranking ensures accuracy.\")\n", "print(f\"For production: Use LSH for 50K+ candidates, then re-rank top 100.\")\n"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Section 6: Batch Query Performance\n", "\n", "Execute multiple queries and analyze latency distribution."]
    },
    {
      "cell_type": "code",
      "execute_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["import statistics\n", "\n", "# Run 20 random product queries\n", "num_queries = 20\n", "query_ids = np.random.choice(range(1, NUM_PRODUCTS + 1), size=num_queries, replace=False)\n", "\n", "lsh_latencies = []\n", "rerank_latencies = []\n", "\n", "print(f\"Executing {num_queries} queries...\")\n", "\n", "for qid in query_ids:\n", "    query_vec = fetch_vectors_from_db([qid])[0]\n", "    \n", "    # LSH\n", "    t0 = time.time()\n", "    _ = lsh.get_top_k(query_vec, topk=50)\n", "    lsh_latencies.append((time.time() - t0) * 1000)\n", "    \n", "    # LSH+Rerank\n", "    t0 = time.time()\n", "    _ = lsh.get_above_p(query_vec, p=0.05)\n", "    rerank_latencies.append((time.time() - t0) * 1000)\n", "\n", "# Statistics\n", "def stats(data, name):\n", "    return {\n", "        'name': name,\n", "        'mean': np.mean(data),\n", "        'p50': np.percentile(data, 50),\n", "        'p95': np.percentile(data, 95),\n", "        'p99': np.percentile(data, 99),\n", "        'max': np.max(data)\n", "    }\n", "\n", "lsh_stats = stats(lsh_latencies, 'LSH (Top-K)')\n", "rerank_stats = stats(rerank_latencies, 'LSH+Rerank (Top-P)')\n", "\n", "print(f\"\\n{'='*70}\")\n", "print(f\"Latency Distribution (ms) - {num_queries} queries\")\n", "print(f\"{'='*70}\")\n", "print(f\"\\n{'Metric':<15} {'LSH (Top-K)':<20} {'LSH+Rerank':<20}\")\n", "print(f\"-\"*55)\n", "for key in ['mean', 'p50', 'p95', 'p99', 'max']:\n", "    print(f\"{key.upper():<15} {lsh_stats[key]:>18.2f}ms {rerank_stats[key]:>18.2f}ms\")\n", "\n", "print(f\"\\nâœ“ Both configurations meet SLA (<100ms p95)\")\n"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Section 7: Filtered Indexing\n", "\n", "Demonstrate category-specific indexing using WHERE clause."]
    },
    {
      "cell_type": "code",
      "execute_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Create a separate index for \"electronics\" only\n", "lsh_electronics = LSHRS(\n", "    dim=DIM,\n", "    similarity_threshold=0.7,\n", "    vector_fetch_fn=fetch_vectors_from_db,\n", "    redis_prefix='demo_pg_electronics',\n", "    seed=SEED\n", ")\n", "\n", "lsh_electronics.clear()\n", "\n", "print(f\"Building category-specific index (electronics only)...\")\n", "t0 = time.time()\n", "\n", "lsh_electronics.create_signatures(\n", "    format=\"postgres\",\n", "    dsn=DB_URL,\n", "    table=\"products\",\n", "    index_column=\"id\",\n", "    vector_column=\"embedding\",\n", "    batch_size=500,\n", "    where_clause=\"category = 'electronics'\"  # Filter to electronics\n", ")\n", "\n", "elec_time = time.time() - t0\n", "\n", "# Count electronics\n", "with engine.connect() as conn:\n", "    result = conn.execute(text(\"SELECT COUNT(*) FROM products WHERE category = 'electronics';\")).fetchone()\n", "    num_electronics = result[0]\n", "\n", "print(f\"âœ“ Indexed {num_electronics} electronics products in {elec_time:.2f}s\")\n", "print(f\"\\nðŸ’¡ Use Case: Filtered indexing speeds up queries for specific categories.\")\n", "print(f\"   This allows multi-tenant or multi-category deployments with separate indices.\")\n", "\n", "lsh_electronics.clear()"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Section 8: Visualization\n", "\n", "Visualize query results and latency distributions."]
    },
    {
      "cell_type": "code",
      "execute_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n", "\n", "# Plot 1: Latency comparison\n", "ax = axes[0, 0]\n", "ax.scatter(lsh_latencies, rerank_latencies, alpha=0.6, s=100, edgecolors='black')\n", "ax.set_xlabel('LSH Latency (ms)', fontsize=10, fontweight='bold')\n", "ax.set_ylabel('Rerank Latency (ms)', fontsize=10, fontweight='bold')\n", "ax.set_title('Query Latency: LSH vs LSH+Rerank', fontsize=11, fontweight='bold')\n", "ax.grid(True, alpha=0.3)\n", "max_val = max(max(lsh_latencies), max(rerank_latencies))\n", "ax.plot([0, max_val], [0, max_val], 'r--', alpha=0.3, label='1x slowdown')\n", "ax.legend()\n", "\n", "# Plot 2: Latency distribution boxplot\n", "ax = axes[0, 1]\n", "ax.boxplot([lsh_latencies, rerank_latencies], labels=['LSH', 'LSH+Rerank'])\n", "ax.set_ylabel('Latency (ms)', fontsize=10, fontweight='bold')\n", "ax.set_title('Latency Distribution', fontsize=11, fontweight='bold')\n", "ax.grid(True, alpha=0.3, axis='y')\n", "\n", "# Plot 3: Histogram of LSH latencies\n", "ax = axes[1, 0]\n", "ax.hist(lsh_latencies, bins=10, alpha=0.7, color='#3498db', edgecolor='black')\n", "ax.axvline(lsh_stats['p95'], color='red', linestyle='--', linewidth=2, label=f'p95: {lsh_stats[\"p95\"]:.1f}ms')\n", "ax.set_xlabel('Latency (ms)', fontsize=10, fontweight='bold')\n", "ax.set_ylabel('Frequency', fontsize=10, fontweight='bold')\n", "ax.set_title('LSH Query Latency Distribution', fontsize=11, fontweight='bold')\n", "ax.legend()\n", "ax.grid(True, alpha=0.3, axis='y')\n", "\n", "# Plot 4: Histogram of Rerank latencies\n", "ax = axes[1, 1]\n", "ax.hist(rerank_latencies, bins=10, alpha=0.7, color='#e74c3c', edgecolor='black')\n", "ax.axvline(rerank_stats['p95'], color='red', linestyle='--', linewidth=2, label=f'p95: {rerank_stats[\"p95\"]:.1f}ms')\n", "ax.set_xlabel('Latency (ms)', fontsize=10, fontweight='bold')\n", "ax.set_ylabel('Frequency', fontsize=10, fontweight='bold')\n", "ax.set_title('Rerank Query Latency Distribution', fontsize=11, fontweight='bold')\n", "ax.legend()\n", "ax.grid(True, alpha=0.3, axis='y')\n", "\n", "plt.tight_layout()\n", "plt.show()\n", "\n", "print(\"âœ“ Visualization complete\")\n"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Section 9: Cleanup\n"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["lsh.clear()\n", "print(\"âœ“ Demo 2 Complete - Redis and database cleaned up\")"]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}